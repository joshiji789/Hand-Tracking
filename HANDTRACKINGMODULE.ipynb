{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2444a047",
   "metadata": {},
   "source": [
    "# $$ Hand Tracking Project $$\n",
    "Name: Anubhav Joshi\n",
    "</br>\n",
    "Indian Institute of Technology Kanpur"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ce6216f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4, 64, 329]\n",
      "[4, 148, 266]\n",
      "[4, 167, 252]\n",
      "[4, 221, 203]\n",
      "[4, 219, 204]\n",
      "[4, 248, 183]\n",
      "[4, 311, 149]\n",
      "[4, 332, 137]\n",
      "[4, 360, 129]\n",
      "[4, 381, 129]\n",
      "[4, 403, 130]\n",
      "[4, 420, 132]\n",
      "[4, 449, 152]\n",
      "[4, 464, 163]\n",
      "[4, 468, 173]\n",
      "[4, 472, 183]\n",
      "[4, 469, 200]\n",
      "[4, 466, 213]\n",
      "[4, 465, 219]\n",
      "[4, 459, 238]\n",
      "[4, 460, 240]\n",
      "[4, 459, 242]\n",
      "[4, 456, 249]\n",
      "[4, 458, 250]\n",
      "[4, 458, 251]\n",
      "[4, 459, 252]\n",
      "[4, 461, 253]\n",
      "[4, 463, 256]\n",
      "[4, 465, 261]\n",
      "[4, 464, 260]\n",
      "[4, 466, 265]\n",
      "[4, 467, 267]\n",
      "[4, 469, 268]\n",
      "[4, 468, 271]\n",
      "[4, 468, 270]\n",
      "[4, 467, 268]\n",
      "[4, 468, 268]\n",
      "[4, 467, 270]\n",
      "[4, 468, 272]\n",
      "[4, 472, 282]\n",
      "[4, 471, 286]\n",
      "[4, 471, 287]\n",
      "[4, 471, 287]\n",
      "[4, 473, 285]\n",
      "[4, 474, 281]\n",
      "[4, 480, 275]\n",
      "[4, 482, 273]\n",
      "[4, 483, 273]\n",
      "[4, 484, 271]\n",
      "[4, 487, 269]\n",
      "[4, 489, 268]\n",
      "[4, 491, 267]\n",
      "[4, 492, 266]\n",
      "[4, 494, 264]\n",
      "[4, 495, 263]\n",
      "[4, 498, 263]\n",
      "[4, 498, 263]\n",
      "[4, 498, 263]\n",
      "[4, 497, 264]\n",
      "[4, 497, 265]\n",
      "[4, 497, 266]\n",
      "[4, 496, 267]\n",
      "[4, 494, 266]\n",
      "[4, 487, 254]\n",
      "[4, 467, 245]\n",
      "[4, 446, 237]\n",
      "[4, 432, 239]\n",
      "[4, 431, 241]\n",
      "[4, 431, 242]\n",
      "[4, 431, 243]\n",
      "[4, 443, 248]\n",
      "[4, 463, 256]\n",
      "[4, 473, 274]\n",
      "[4, 473, 277]\n",
      "[4, 471, 275]\n",
      "[4, 469, 275]\n",
      "[4, 467, 275]\n",
      "[4, 464, 275]\n",
      "[4, 462, 275]\n",
      "[4, 459, 273]\n",
      "[4, 457, 272]\n",
      "[4, 456, 271]\n",
      "[4, 453, 270]\n",
      "[4, 451, 269]\n",
      "[4, 450, 269]\n",
      "[4, 449, 269]\n",
      "[4, 444, 260]\n",
      "[4, 425, 250]\n",
      "[4, 393, 235]\n",
      "[4, 390, 237]\n",
      "[4, 391, 237]\n",
      "[4, 392, 239]\n",
      "[4, 397, 241]\n",
      "[4, 419, 249]\n",
      "[4, 435, 259]\n",
      "[4, 438, 268]\n",
      "[4, 438, 265]\n",
      "[4, 437, 264]\n",
      "[4, 438, 266]\n",
      "[4, 438, 266]\n",
      "[4, 434, 262]\n",
      "[4, 403, 248]\n",
      "[4, 377, 237]\n",
      "[4, 379, 241]\n",
      "[4, 426, 272]\n",
      "[4, 428, 263]\n",
      "[4, 420, 251]\n",
      "[4, 385, 235]\n",
      "[4, 379, 240]\n",
      "[4, 385, 241]\n",
      "[4, 411, 259]\n",
      "[4, 428, 273]\n",
      "[4, 430, 273]\n",
      "[4, 426, 266]\n",
      "[4, 399, 252]\n",
      "[4, 432, 277]\n",
      "[4, 433, 276]\n",
      "[4, 435, 275]\n",
      "[4, 434, 274]\n",
      "[4, 434, 276]\n",
      "[4, 434, 277]\n",
      "[4, 434, 277]\n",
      "[4, 434, 277]\n",
      "[4, 433, 277]\n",
      "[4, 430, 270]\n",
      "[4, 420, 255]\n",
      "[4, 381, 250]\n",
      "[4, 369, 252]\n",
      "[4, 367, 258]\n",
      "[4, 357, 265]\n",
      "[4, 348, 274]\n",
      "[4, 337, 290]\n",
      "[4, 314, 305]\n",
      "[4, 289, 324]\n",
      "[4, 238, 375]\n",
      "[4, 203, 420]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_20176/868688449.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m    125\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    126\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0m__name__\u001b[0m\u001b[1;33m==\u001b[0m\u001b[1;34m'__main__'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 127\u001b[1;33m     \u001b[0mmain\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_20176/868688449.py\u001b[0m in \u001b[0;36mmain\u001b[1;34m()\u001b[0m\n\u001b[0;32m    103\u001b[0m         \u001b[0msuccess\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mimg\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcap\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    104\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 105\u001b[1;33m         \u001b[0mimg\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdetector\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfindHands\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    106\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    107\u001b[0m         \u001b[0mlmList\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdetector\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfindPosition\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_20176/868688449.py\u001b[0m in \u001b[0;36mfindHands\u001b[1;34m(self, img, draw)\u001b[0m\n\u001b[0;32m     55\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     56\u001b[0m         \u001b[1;31m# Process the hand Image imgRGB\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 57\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mresults\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhands\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mprocess\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimgRGB\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     58\u001b[0m         \u001b[1;31m#print(results.multi_hand_landmarks)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     59\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\mediapipe\\python\\solutions\\hands.py\u001b[0m in \u001b[0;36mprocess\u001b[1;34m(self, image)\u001b[0m\n\u001b[0;32m    151\u001b[0m     \"\"\"\n\u001b[0;32m    152\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 153\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mprocess\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput_data\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m{\u001b[0m\u001b[1;34m'image'\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mimage\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\mediapipe\\python\\solution_base.py\u001b[0m in \u001b[0;36mprocess\u001b[1;34m(self, input_data)\u001b[0m\n\u001b[0;32m    362\u001b[0m                                      data).at(self._simulated_timestamp))\n\u001b[0;32m    363\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 364\u001b[1;33m     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_graph\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwait_until_idle\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    365\u001b[0m     \u001b[1;31m# Create a NamedTuple object where the field names are mapping to the graph\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    366\u001b[0m     \u001b[1;31m# output stream names.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "#%% Hand Tracking in real time\n",
    "'''\n",
    "\n",
    " mediapipe guithub by Google\n",
    " Hand tracking ----> Palm Detection and Hand Landmark\n",
    "              Complete image of hand,   21 different landmark manually notated 30K notations of hand\n",
    "\n",
    "'''\n",
    "\n",
    "''' Static_image_mode=Defalt False----> images as a video stream.\n",
    "                                                      first image detect and then \n",
    "                                                      localize localize the landmarks\n",
    "                                                      in same image.\n",
    "                                                      is set to True, hand detection runs\n",
    "                                                      on every input image, ideal for processing\n",
    "                                                      a batch of static, possibly unrelated, images.\n",
    "    Max_num_Hands=Maximum number of hands to detect.\n",
    "    Model_complexity= Landmarks accuracy as well as inference lantency generally go up with the model\n",
    "                      complexity. default=1\n",
    "    Min_Detection_Confidence=From the hand detection model for the detection to be considered successful.\n",
    "    Min_Tracking_Confidence= Hand landmarks to be considered tracked successfull or otherwise hand \n",
    "                             detection will be invoked autimatically on the next input image.\n",
    "'''\n",
    "# Intall opencv-python , mediapipe\n",
    "\n",
    "# Importing Libraries\n",
    "import cv2\n",
    "import mediapipe as mp\n",
    "import time\n",
    "\n",
    "# Class hand Detector\n",
    "class handDetector():\n",
    "    \n",
    "    def __init__(self,mode=False,maxHands=2,modelComplexity=1,detectionCon=0.5,trackCon=0.5):\n",
    "\n",
    "        self.mode=mode\n",
    "        self.maxHands=maxHands\n",
    "        \n",
    "        self.modelComplexity=modelComplexity\n",
    "        \n",
    "        self.detectionCon=detectionCon\n",
    "        self.trackCon=trackCon\n",
    "        \n",
    "        # mp.solutions.hands---> import mediapipe librarie and use solutions.hands\n",
    "        \n",
    "        self.mpHands=mp.solutions.hands\n",
    "        self.hands=self.mpHands.Hands(self.mode, self.maxHands, self.modelComplexity,self.detectionCon, self.trackCon)\n",
    "        self.mpDraw=mp.solutions.drawing_utils\n",
    "\n",
    "    \n",
    "    def findHands(self,img,draw=True):\n",
    "        \n",
    "        # Convert image BGR to RGB\n",
    "        imgRGB=cv2.cvtColor(img,cv2.COLOR_BGR2RGB)\n",
    "        \n",
    "        # Process the hand Image imgRGB\n",
    "        self.results=self.hands.process(imgRGB)    \n",
    "        #print(results.multi_hand_landmarks)\n",
    "    \n",
    "        if self.results.multi_hand_landmarks:\n",
    "            \n",
    "            #Connecting Hand Landmarks\n",
    "            for handLms in self.results.multi_hand_landmarks:\n",
    "                \n",
    "                if draw:\n",
    "                    self.mpDraw.draw_landmarks(img,handLms,self.mpHands.HAND_CONNECTIONS)\n",
    "        \n",
    "        #Return Hand image with located hand landmarks with connections\n",
    "        return img\n",
    "    \n",
    "    def findPosition(self,img,handNo=0,draw=True):\n",
    "        \n",
    "        lmList=[]\n",
    "        if self.results.multi_hand_landmarks:\n",
    "            \n",
    "            myHand=self.results.multi_hand_landmarks[handNo]\n",
    "            \n",
    "            for ide,lm in enumerate(myHand.landmark):\n",
    "\n",
    "                h, w, c=img.shape\n",
    "\n",
    "                cx,cy=int(lm.x*w),int(lm.y*h)\n",
    "\n",
    "                #print(ide,cx,cy)\n",
    "                lmList.append([ide,cx,cy])\n",
    "                \n",
    "                if draw:\n",
    "                    cv2.circle(img,(cx,cy),5,(255,0,0),cv2.FILLED)\n",
    "\n",
    "        return lmList\n",
    "    \n",
    "def main():\n",
    "    # Time for FPS calculation\n",
    "    pTime=0\n",
    "    cTime=0\n",
    "    \n",
    "    cap=cv2.VideoCapture(0) # Webcam For video \n",
    "    detector=handDetector() # Object of Class\n",
    "    \n",
    "    while True:\n",
    "        \n",
    "        # Read image\n",
    "        success,img=cap.read()\n",
    "        \n",
    "        img=detector.findHands(img)\n",
    "        \n",
    "        lmList=detector.findPosition(img)\n",
    "        \n",
    "        # Print Location of 4th landmark.\n",
    "        if len(lmList)!=0:\n",
    "            print(lmList[4])\n",
    "        \n",
    "        # Calculation of Fps\n",
    "        cTime=time.time()\n",
    "        fps=1/(cTime-pTime)\n",
    "        pTime=cTime\n",
    "        \n",
    "        # Put fps Info. to the Web video with hand detection.\n",
    "        cv2.putText(img,str(int(fps)),(10,70),cv2.FONT_HERSHEY_PLAIN,\n",
    "                    3,(255,0,0),3)\n",
    "    \n",
    "        # Show Image\n",
    "        cv2.imshow(\"Image\",img)\n",
    "        cv2.waitKey(1)\n",
    "\n",
    "if __name__=='__main__':\n",
    "    main()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d53c6dd9",
   "metadata": {},
   "source": [
    "---\n",
    "---"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
